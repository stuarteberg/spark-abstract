The emerging field of connectomics aims to unlock the mysteries of brain by understanding the connectivity between neurons.
To map this connectivity, we acquire thousands of electron microscopy (EM) images with nanometer-scale resolution. Once analyzed, these images have the potential to reveal neuronal shapes synaptic inter-neuron connections.

However, extraction of the connectivity information from such large-scale image data is very time consuming.
Imaging the brain of even a tiny organism like the fruit fly yields terabytes of data.
It can take years of manual effort to examine such image volumes and trace their neuronal connections.

To alleviate the time-consuming manual effort required to extract neural connectivity, we apply cutting-edge image segmentation algorithms to semi-automatically segment neurons from EM datasets.

In particular, we propose a novel strategy to segment those large neurons whose volumes exceed the capacity of a single machine.
Furthermore, our implementation is robust to the potential segmentation errors that inevitably arise from such large datasets, such as anomalies in the raw image data, or regions of data for which we lack representative training samples.

To process a very large dataset, we implement a Spark application that runs a batch segmentation, at scale, on several overlapping subvolumes and also implements a global algorithm for stitching these subvolumes together.

Additionally, we implement tools for analyzing the quality of this segmentation at scale.
Our results correctly segment significant portions of many neurons spanning a large dataset.

Our implementation exposes flexible segmentation configuration and supports a plugin architecture to allow parts of the workflow to be replaced with custom implementations.
Other key features of our solution include
a) fast compression and serialization of large numpy datastructures,
b) rollback mechanisms to enable mid-application recovery needed for long-running Spark applications,
and 3) a library for reading/writing data through the image-oriented, versioned data service called DVID.
